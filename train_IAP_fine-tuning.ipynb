{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import pytorch_lightning as pl\n",
    "import ML_library        as MLL\n",
    "import matplotlib.pyplot as plt\n",
    "import matgl\n",
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from __future__                import annotations\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from matgl.ext.pymatgen        import Structure2Graph, get_element_list\n",
    "from matgl.graph.data          import M3GNetDataset, MGLDataLoader, collate_fn_efs\n",
    "from matgl.utils.training      import PotentialLightningModule\n",
    "\n",
    "# To suppress warnings for clearer output\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T08:27:27.147574730Z",
     "start_time": "2024-09-18T08:27:24.069664261Z"
    }
   },
   "id": "779806c81501309a",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-18T08:27:27.152490681Z",
     "start_time": "2024-09-18T08:27:27.150481147Z"
    }
   },
   "id": "e5618a095f97c090",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Whether to include charge (which) or not\n",
    "charged = 1\n",
    "\n",
    "model_load_path = 'M3GNet-MP-2021.2.8-PES'\n",
    "model_save_path = f'finetuned_model-charge{charged}'\n",
    "\n",
    "# 0: material, 1: charge state, 2: ionic step\n",
    "depth = 1\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Stress weight for training\n",
    "stress_weight = 0.7  # 0.7\n",
    "\n",
    "# Ratios for diving training data\n",
    "test_ratio       = 0.2\n",
    "validation_ratio = 0.2\n",
    "\n",
    "# Number of epoch for re-training\n",
    "max_epochs = 1000\n",
    "\n",
    "# Learning-rate for re-training\n",
    "lr = 1e-4\n",
    "\n",
    "dpi = 100\n",
    "\n",
    "# Version of training you specifically want to analyze\n",
    "current_version = 0\n",
    "\n",
    "# Each folder names a new column, and structure, energy, forces and stresses\n",
    "# of each ionic step are loaded\n",
    "\n",
    "# Path to dataset, structured as:\n",
    "# path_to_dataset\n",
    "#     material_i\n",
    "#         defect_i\n",
    "#             simulation_i (containing vasprun.xml)\n",
    "\n",
    "path_to_dataset = '/home/cibran/Desktop/defects/no-pressure/HSE06+D3+SOC'\n",
    "#path_to_dataset = '../../../Desktop/CeO2-data'\n",
    "\n",
    "# Create and save as a dictionary\n",
    "model_parameters = {\n",
    "    'model_load_path':  model_load_path,\n",
    "    'model_save_path':  model_save_path,\n",
    "    'charged':          charged,\n",
    "    'depth':            depth,\n",
    "    'batch_size':       batch_size,\n",
    "    'stress_weight':    stress_weight,\n",
    "    'test_ratio':       test_ratio,\n",
    "    'validation_ratio': validation_ratio,\n",
    "    'max_epochs':       max_epochs,\n",
    "    'lr':               lr,\n",
    "    'path_to_dataset':  path_to_dataset,\n",
    "}\n",
    "\n",
    "# Write the dictionary to the file in JSON format\n",
    "with open(f'{model_save_path}/model_parameters.json', 'w') as json_file:\n",
    "    json.dump(model_parameters, json_file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d607ff9dfce08356"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load simulation data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6f4b02404eec71a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Extract the data\n",
    "m3gnet_dataset = MLL.extract_vaspruns_dataset(path_to_dataset, charged=charged)\n",
    "#m3gnet_dataset = MLL.extract_OUTCAR_dataset(path_to_dataset)\n",
    "m3gnet_dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dadda8b91bfdbbcd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split data into train-validation-test sets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8798701c99c4714f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decide if we split in terms of mateiral, defect state or simulation directly"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce39775a0eeb0347"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Clone (copy) the DataFrame\n",
    "#m3gnet_dataset = source_m3gnet_dataset.copy()\n",
    "\n",
    "# Remove the outer (top-level) column index up to depth-1 level\n",
    "for i in range(depth):\n",
    "    m3gnet_dataset.columns = m3gnet_dataset.columns.droplevel(0)\n",
    "m3gnet_dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ab93b068fbcff6b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Splitting into train-validation-test sets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0461839714889c7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check if data has been already split, else do it randomly\n",
    "\n",
    "path_to_test_labels       = 'test_labels.txt'\n",
    "path_to_validation_labels = 'validation_labels.txt'\n",
    "path_to_train_labels      = 'train_labels.txt'\n",
    "\n",
    "if os.path.exists(path_to_test_labels) and os.path.exists(path_to_validation_labels) and os.path.exists(path_to_train_labels):\n",
    "    # Read labels splitting (which are strings)\n",
    "    test_labels       = np.genfromtxt(path_to_test_labels,       dtype='str').tolist()\n",
    "    validation_labels = np.genfromtxt(path_to_validation_labels, dtype='str').tolist()\n",
    "    train_labels      = np.genfromtxt(path_to_train_labels,      dtype='str').tolist()\n",
    "else:\n",
    "    # Define unique labels, wrt the outer column\n",
    "    unique_labels = np.unique(m3gnet_dataset.columns.get_level_values(0))\n",
    "\n",
    "    # Shuffle the list of unique labels\n",
    "    np.random.shuffle(unique_labels)\n",
    "\n",
    "    # Define the sizes of every set\n",
    "    # Corresponds to the size wrt the number of unique materials in the dataset\n",
    "    test_size       = int(test_ratio       * len(unique_labels))\n",
    "    validation_size = int(validation_ratio * len(unique_labels))\n",
    "\n",
    "    test_labels       = unique_labels[:test_size]\n",
    "    validation_labels = unique_labels[test_size:test_size+validation_size]\n",
    "    train_labels      = unique_labels[test_size+validation_size:]\n",
    "    \n",
    "    # Save this splitting for transfer-learning approaches\n",
    "    np.savetxt(path_to_test_labels,       test_labels,       fmt='%s')\n",
    "    np.savetxt(path_to_validation_labels, validation_labels, fmt='%s')\n",
    "    np.savetxt(path_to_train_labels,      train_labels,      fmt='%s')\n",
    "\n",
    "# Use the loaded/computed labels to generate split datasets\n",
    "test_dataset       = m3gnet_dataset[test_labels]\n",
    "validation_dataset = m3gnet_dataset[validation_labels]\n",
    "train_dataset      = m3gnet_dataset[train_labels]\n",
    "del m3gnet_dataset\n",
    "\n",
    "n_test       = np.shape(test_dataset)[1]\n",
    "n_validation = np.shape(validation_dataset)[1]\n",
    "n_train      = np.shape(train_dataset)[1]\n",
    "\n",
    "print(f'Using {n_train} samples to train, {n_validation} to evaluate, and {n_test} to test')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67684f945cc8e436"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert into graph database"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78260fabd76e5705"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for i in range(3):  # Iterate over train-validation-test sets\n",
    "    name    = ['train', 'val', 'test'][i]\n",
    "    dataset = [train_dataset, validation_dataset, test_dataset][i]\n",
    "\n",
    "    # Extract data from dataset\n",
    "    structures    = dataset.loc['structure'].values.tolist()\n",
    "    element_types = get_element_list(structures)\n",
    "    converter     = Structure2Graph(element_types=element_types, cutoff=5.0)\n",
    "    \n",
    "    # Define data labels from dataset\n",
    "    if stress_weight == 0:\n",
    "        stresses = [np.zeros((3, 3)).tolist() for s in structures]\n",
    "    else:\n",
    "        stresses = dataset.loc['stress'].values.tolist()\n",
    "\n",
    "    labels = {\n",
    "        'energies': dataset.loc['energy'].values.tolist(),\n",
    "        'forces':   dataset.loc['force'].values.tolist(),\n",
    "        'stresses': stresses,\n",
    "    }\n",
    "    \n",
    "    # Generate dataset\n",
    "    data = M3GNetDataset(\n",
    "        filename=f'dgl_graph-{name}.bin',\n",
    "        filename_line_graph=f'dgl_line_graph-{name}.bin',\n",
    "        filename_state_attr=f'state_attr-{name}.pt',\n",
    "        filename_labels=f'labels-{name}.json',\n",
    "        threebody_cutoff=4.0,\n",
    "        structures=structures,\n",
    "        converter=converter,\n",
    "        labels=labels,\n",
    "        name=f'M3GNetDataset-{name}',\n",
    "    )\n",
    "    all_data.append(data)\n",
    "\n",
    "train_data, val_data, test_data = all_data\n",
    "del all_data, test_dataset, validation_dataset, train_dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28d41455e0291455"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = MGLDataLoader(\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    test_data=test_data,\n",
    "    collate_fn=collate_fn_efs,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=16,\n",
    "    pin_memory=False  # True for more rapid data transfer to GPU, pinning memory to RAM\n",
    ")\n",
    "del train_data, val_data, test_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a0518591fada833"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Retrain model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d85e5b3eed64b62e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Download a pre-trained M3GNet\n",
    "m3gnet_nnp       = matgl.load_model(model_load_path)\n",
    "model_pretrained = m3gnet_nnp.model\n",
    "\n",
    "# Stress and site-wise are added to training loss\n",
    "# Stresses are being computed (calc_stress=True)\n",
    "lit_module_finetune = PotentialLightningModule(model=model_pretrained,\n",
    "                                               stress_weight=stress_weight,\n",
    "                                               loss='mse_loss',\n",
    "                                               lr=lr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-18T08:40:04.354613294Z"
    }
   },
   "id": "33c8bb3cf9c66427",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# If you wish to disable GPU or MPS (M1 mac) training, use the accelerator='cpu' kwarg.\n",
    "# accelerator='auto' selects the appropriate Accelerator\n",
    "logger  = CSVLogger('logs',\n",
    "                    name='M3GNet_finetuning')\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,\n",
    "                     accelerator='auto',\n",
    "                     logger=logger,\n",
    "                     inference_mode=False)\n",
    "\n",
    "trainer.fit(model=lit_module_finetune,\n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loader\n",
    "           )\n",
    "\n",
    "# Save trained model\n",
    "lit_module_finetune.model.save(model_save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-18T08:40:04.356190705Z"
    }
   },
   "id": "2ea8bc35a28e91c8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analyze metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef9e163c70f7bcc9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# E_MAE = meV/atom, F_MAE = eV/A, S_MAE = GPa\n",
    "trainer.test(model=lit_module_finetune,\n",
    "            dataloaders=test_loader\n",
    "           )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-18T08:40:04.357729003Z"
    }
   },
   "id": "5a9f0ad509b5b499",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-18T08:40:04.359150449Z"
    }
   },
   "id": "fbd88415072ab1ab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "current_version = 0\n",
    "# Read the CSV file\n",
    "path_to_csv = f'logs/M3GNet_finetuning/version_{current_version}'\n",
    "df = pd.read_csv(f'{path_to_csv}/metrics.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-18T08:40:04.360253759Z"
    }
   },
   "id": "9ea916d30e0e4102",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3134249",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2024-09-18T08:40:04.372752859Z"
    }
   },
   "outputs": [],
   "source": [
    "# NaN to zero\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Calculate the sum of every two consecutive rows\n",
    "df = df.groupby(df.index // 2).sum()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643704df",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-18T08:40:04.372923481Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the list of loss column names\n",
    "loss_columns = [col for col in df.columns if col.startswith('val_') or col.startswith('train_')]\n",
    "\n",
    "# Create a figure and axis\n",
    "fig = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot each loss\n",
    "for loss_column in loss_columns:\n",
    "    plt.plot(df.index, np.log(df[loss_column]), label=loss_column)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc=(1.01, 0))\n",
    "plt.savefig(f'm3gnet_loss.eps', dpi=dpi, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85d562",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-18T08:40:04.373036417Z"
    }
   },
   "outputs": [],
   "source": [
    "df['val_Energy_MAE'].iloc[-2], df['val_Force_MAE'].iloc[-2], df['val_Stress_MAE'].iloc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc01f877",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-18T08:40:04.373114130Z"
    }
   },
   "outputs": [],
   "source": [
    "df['val_Energy_MAE'].iloc[-1], df['val_Force_MAE'].iloc[-1], df['val_Stress_MAE'].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e76beb",
   "metadata": {},
   "source": [
    "# Cleanup the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7147751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:46:49.077033631Z",
     "start_time": "2024-07-23T19:46:48.828836849Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m patterns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdgl_graph*.bin\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdgl_line_graph*.bin\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstate_attr*.pt\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels*.json\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m*labels.txt\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m pattern \u001B[38;5;129;01min\u001B[39;00m patterns:\n\u001B[0;32m----> 5\u001B[0m     files \u001B[38;5;241m=\u001B[39m \u001B[43mglob\u001B[49m\u001B[38;5;241m.\u001B[39mglob(pattern)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m files:\n\u001B[1;32m      7\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mNameError\u001B[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "# This code just performs cleanup for this notebook from temporal files\n",
    "\n",
    "patterns = ['dgl_graph*.bin', 'dgl_line_graph*.bin', 'state_attr*.pt', 'labels*.json', '*labels.txt']\n",
    "for pattern in patterns:\n",
    "    files = glob.glob(pattern)\n",
    "    for file in files:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "#shutil.rmtree('logs')\n",
    "#shutil.rmtree('trained_model')\n",
    "#shutil.rmtree('finetuned_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
