{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2cacba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import pytorch_lightning as pl\n",
    "import ML_library        as MLL\n",
    "import matplotlib.pyplot as plt\n",
    "import matgl\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import glob\n",
    "\n",
    "from os                        import path\n",
    "from __future__                import annotations\n",
    "from dgl.data.utils            import split_dataset\n",
    "from mp_api.client             import MPRester\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from matgl.ext.pymatgen        import Structure2Graph, get_element_list\n",
    "from matgl.graph.data          import M3GNetDataset, MGLDataLoader, collate_fn_efs\n",
    "from matgl.models              import M3GNet\n",
    "from matgl.utils.training      import PotentialLightningModule\n",
    "\n",
    "# To suppress warnings for clearer output\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcb9beee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_path = 'm3gnet_dataset.xlsx'\n",
    "model_load_path = 'M3GNet-MP-2021.2.8-PES'\n",
    "model_save_path = 'finetuned_model'\n",
    "\n",
    "# 0: material, 1: charge state, 2: ionic step\n",
    "depth = 1\n",
    "\n",
    "# Ratios for diving training data\n",
    "test_ratio       = 0.2\n",
    "validation_ratio = 0.2\n",
    "\n",
    "# Number of epoch for re-training\n",
    "max_epochs = 30\n",
    "\n",
    "dpi = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5361fc5f",
   "metadata": {},
   "source": [
    "# Load simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "319d94a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BiSBr\n",
      "\tvac_1_Bi_0\n",
      "\tvac_1_Bi_2\n",
      "\tvac_2_S_-2\n",
      "\tvac_2_S_1\n",
      "\tvac_3_Br_-1\n",
      "\tvac_3_Br_0\n",
      "\n",
      "BiSeBr\n",
      "\n",
      "BiSeI\n",
      "\n",
      "BiSI\n",
      "\tas_1_Bi_on_S_-2\n",
      "\tas_1_Bi_on_S_0\n",
      "\tas_1_I_on_Bi_0\n",
      "\tas_1_S_on_Bi_0\n",
      "\tas_2_Bi_on_I_0\n",
      "\tas_2_I_on_S_0\n",
      "\tas_2_S_on_I_-1\n",
      "\tas_2_S_on_I_0\n",
      "\tas_2_S_on_I_4\n",
      "\tsupercell\n",
      "\tvac_1_Bi_-1\n",
      "\tvac_1_Bi_-2\n",
      "\tvac_1_Bi_-3\n",
      "\tvac_1_Bi_0\n",
      "\tvac_1_Bi_1\n",
      "\tvac_1_Bi_2\n",
      "\tvac_1_Bi_3\n",
      "\tvac_2_S_-1\n",
      "\tvac_2_S_-2\n",
      "\tvac_2_S_0\n",
      "\tvac_2_S_1\n",
      "\tvac_2_S_2\n",
      "\tvac_3_I_-1\n",
      "\tvac_3_I_0\n",
      "\tvac_3_I_1\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/m5/whlk89kx5x17v9g6d328s3f40000gn/T/ipykernel_24016/3462588797.py\", line 16, in <module>\n",
      "    source_m3gnet_dataset = MLL.extract_vaspruns_dataset(path_to_dataset)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/cibran/Work/UCL/m3gnet/ML_library.py\", line 171, in extract_vaspruns_dataset\n",
      "NameError: name 'pd' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "                                              ^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# Each folder names a new column, and structure, energy, forces and stresses\n",
    "# of each ionic step are loaded\n",
    "\n",
    "if path.exists(data_train_path):\n",
    "    # Load data for model training\n",
    "    m3gnet_dataset = pd.read_excel(data_train_path, index_col=0, header=[0,1,2])\n",
    "else:\n",
    "    # Path to dataset, structured as:\n",
    "    # path_to_dataset\n",
    "    #     material_i\n",
    "    #         defect_i\n",
    "    #             simulation_i (containing vasprun.xml)\n",
    "    path_to_dataset = '../../../Desktop/defects/ssc'\n",
    "\n",
    "    # Extract the data\n",
    "    source_m3gnet_dataset = MLL.extract_vaspruns_dataset(path_to_dataset)\n",
    "    #source_m3gnet_dataset.to_excel(data_train_path)\n",
    "\n",
    "source_m3gnet_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e7077a",
   "metadata": {},
   "source": [
    "# Split data into train-validation-test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669793ea",
   "metadata": {},
   "source": [
    "### Decide if we split in terms of mateiral, defect state or simulation directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153bf13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone (copy) the DataFrame\n",
    "m3gnet_dataset = source_m3gnet_dataset.copy()\n",
    "\n",
    "# Remove the outer (top-level) column index up to depth-1 level\n",
    "for i in range(depth):\n",
    "    m3gnet_dataset.columns = m3gnet_dataset.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29e14f",
   "metadata": {},
   "source": [
    "### Splitting into train-validation-test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe37f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define unique labels, wrt the outer column\n",
    "unique_labels = np.unique(m3gnet_dataset.columns.get_level_values(0))\n",
    "\n",
    "# Shuffle the list of unique labels\n",
    "np.random.shuffle(unique_labels)\n",
    "\n",
    "# Define the sizes of every sets\n",
    "# Corresponds to the size wrt the number of unique materials in the dataset\n",
    "test_size       = int(test_ratio       * len(unique_labels))\n",
    "validation_size = int(validation_ratio * len(unique_labels))\n",
    "\n",
    "test_labels       = unique_labels[:test_size]\n",
    "validation_labels = unique_labels[test_size:test_size+validation_size]\n",
    "train_labels      = unique_labels[test_size+validation_size:]\n",
    "\n",
    "# Use the computed indexes to generate train and test sets\n",
    "test_dataset       = m3gnet_dataset[test_labels]\n",
    "validation_dataset = m3gnet_dataset[validation_labels]\n",
    "train_dataset      = m3gnet_dataset[train_labels]\n",
    "\n",
    "n_test       = np.shape(test_dataset)[1]\n",
    "n_validation = np.shape(validation_dataset)[1]\n",
    "n_train      = np.shape(train_dataset)[1]\n",
    "\n",
    "print(f'Using {n_train} samples to train, {n_validation} to evaluate, and {n_test} to test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ae939",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for i in range(3):  # Iterate over train-validation-test sets\n",
    "    name    = ['train', 'val', 'test'][i]\n",
    "    dataset = [train_dataset, validation_dataset, test_dataset][i]\n",
    "    \n",
    "    # Extract data from dataset\n",
    "    labels = {\n",
    "        \"energies\": dataset.loc['energy'].values.tolist(),\n",
    "        \"forces\":   dataset.loc['force'].values.tolist(),\n",
    "        \"stresses\": dataset.loc['stress'].values.tolist(),\n",
    "    }\n",
    "    \n",
    "    structures    = dataset.loc['structure'].values.tolist()\n",
    "    element_types = get_element_list(structures)\n",
    "    converter     = Structure2Graph(element_types=element_types, cutoff=5.0)\n",
    "    print(len(structures))\n",
    "    # Generate dataset\n",
    "    data = M3GNetDataset(\n",
    "        filename=f'dgl_graph-{name}.bin',\n",
    "        filename_line_graph=f'dgl_line_graph-{name}.bin',\n",
    "        filename_state_attr=f'state_attr-{name}.pt',\n",
    "        filename_labels=f'labels-{name}.json',\n",
    "        threebody_cutoff=4.0,\n",
    "        structures=structures,\n",
    "        converter=converter,\n",
    "        labels=labels,\n",
    "        name=f'M3GNetDataset-{name}',\n",
    "    )\n",
    "    all_data.append(data)\n",
    "\n",
    "train_data, val_data, test_data = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9264d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = MGLDataLoader(\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    test_data=test_data,\n",
    "    collate_fn=collate_fn_efs,\n",
    "    batch_size=2,\n",
    "    num_workers=1,\n",
    ")\n",
    "model = M3GNet(\n",
    "    element_types=element_types,\n",
    "    is_intensive=False,\n",
    ")\n",
    "lit_module = PotentialLightningModule(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fb577b",
   "metadata": {},
   "source": [
    "# Retrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee82439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download a pre-trained M3GNet\n",
    "m3gnet_nnp          = matgl.load_model(model_load_path)\n",
    "model_pretrained    = m3gnet_nnp.model\n",
    "lit_module_finetune = PotentialLightningModule(model=model_pretrained, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ffedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you wish to disable GPU or MPS (M1 mac) training, use the accelerator='cpu' kwarg.\n",
    "# accelerator='auto' selects the appropriate Accelerator\n",
    "logger  = CSVLogger('logs',\n",
    "                    name='M3GNet_finetuning')\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,\n",
    "                     accelerator='auto',\n",
    "                     logger=logger,\n",
    "                     inference_mode=False)\n",
    "\n",
    "trainer.fit(model=lit_module_finetune,\n",
    "            train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loader\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model_pretrained.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f451f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access training metrics\n",
    "training_metrics = trainer.callback_metrics\n",
    "\n",
    "# Access test metrics\n",
    "test_metrics = trainer.logged_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a914e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version of trainng you specifically want to analyze\n",
    "current_version = 0\n",
    "\n",
    "# Read the CSV file\n",
    "path_to_csv = f'logs/M3GNet_finetuning/version_{current_version}'\n",
    "df = pd.read_csv(f'{path_to_csv}/metrics.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3134249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN to cero\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Calculate the sum of every two consecutive rows\n",
    "df = df.groupby(df.index // 2).sum()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643704df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of loss column names\n",
    "loss_columns = [col for col in df.columns if col.startswith('val_') or col.startswith('train_')]\n",
    "\n",
    "# Create a figure and axis\n",
    "fig = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot each loss\n",
    "for loss_column in loss_columns:\n",
    "    plt.plot(df.index, np.log(df[loss_column]), label=loss_column)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc=(1.01, 0))\n",
    "plt.savefig(f'm3gnet_loss.eps', dpi=dpi, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['val_Energy_MAE'].iloc[-1], df['val_Force_MAE'].iloc[-1], df['val_Stress_MAE'].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59112d79",
   "metadata": {},
   "source": [
    "# Cleanup the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340deace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code just performs cleanup for this notebook from temporal files\n",
    "\n",
    "patterns = ['dgl_graph*.bin', 'dgl_line_graph*.bin', 'state_attr*.pt', 'labels*.json']\n",
    "for pattern in patterns:\n",
    "    files = glob.glob(pattern)\n",
    "    for file in files:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "#shutil.rmtree('logs')\n",
    "#shutil.rmtree('trained_model')\n",
    "#shutil.rmtree('finetuned_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
